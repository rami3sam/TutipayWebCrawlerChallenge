/*
 * This Java source file was generated by the Gradle 'init' task.
 */
package com.rami3sam.crawler;

import java.util.HashSet;
import java.util.LinkedList;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;

public class Main {
    static String SEED_URL = "http://localhost:8000/dir/test.html";
    static int CRAWL_LIMIT = 100;
    static volatile HashSet crawledURLs = new HashSet();
    static volatile LinkedList<String> newURLs = new LinkedList<>();

    public static void main(String[] args) throws InterruptedException {
        newURLs.add(SEED_URL);

        ExecutorService executor = Executors.newFixedThreadPool(5);//creating a pool of 5 threads
        for (int i = 0; i < CRAWL_LIMIT; i++) {
            String currentURL;

            while (newURLs.isEmpty()) {
                //System.out.println(Main.newURLs);
            }

            currentURL = newURLs.getFirst();
            newURLs.removeFirst();


            CrawlerRunnable worker = new CrawlerRunnable(currentURL);

            executor.execute(worker);//calling execute method of ExecutorService
        }
        executor.shutdown();
        while (!executor.isTerminated()) {
        }

        System.out.println("************\n");

    }
}
